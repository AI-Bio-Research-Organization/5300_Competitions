{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Optimized Korean Review Decoding Script\n",
    "   Adjusted for Training Time Reduction on Colab with T4 GPU.\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "FGBiCAFskWWz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Install dependencies (if needed in Colab)\n",
    "!pip install msal bitsandbytes msal_extensions\n",
    "!pip install -U --upgrade accelerate transformers"
   ],
   "metadata": {
    "id": "7gKYJ8dHkeDy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bf21ec13-2226-4ae4-eb85-4be1211121ae",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:16.881904Z",
     "start_time": "2025-01-18T15:01:12.543630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: msal in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (1.31.1)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (0.45.0)\n",
      "Requirement already satisfied: msal_extensions in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from msal) (2.32.3)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal) (2.10.1)\n",
      "Requirement already satisfied: cryptography<46,>=2.5 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from msal) (44.0.0)\n",
      "Requirement already satisfied: torch in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from bitsandbytes) (2.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from bitsandbytes) (2.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from msal_extensions) (2.10.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from cryptography<46,>=2.5->msal) (1.17.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from portalocker<3,>=1.4->msal_extensions) (305.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from requests<3,>=2.0.0->msal) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from requests<3,>=2.0.0->msal) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from requests<3,>=2.0.0->msal) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from requests<3,>=2.0.0->msal) (2024.12.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from torch->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from torch->bitsandbytes) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from torch->bitsandbytes) (2024.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from cffi>=1.12->cryptography<46,>=2.5->msal) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (4.48.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from accelerate) (0.26.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from torch>=2.0.0->accelerate) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\didie\\anaconda3\\envs\\dacon_vision_ai\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import gc\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from msal import PublicClientApplication\n",
    "from msal_extensions import FilePersistence, PersistedTokenCache\n",
    "import requests\n",
    "from accelerate import infer_auto_device_map\n",
    "from transformers import logging\n",
    "import os\n",
    "from accelerate import infer_auto_device_map\n",
    "from transformers import logging"
   ],
   "metadata": {
    "id": "dfDwMeLhkZPt",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:24.379919Z",
     "start_time": "2025-01-18T15:01:16.902667Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset Loader Class\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.iloc[idx]['input'], self.data.iloc[idx]['output']"
   ],
   "metadata": {
    "id": "4nr_3vTnkaXp",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:24.672294Z",
     "start_time": "2025-01-18T15:01:24.667865Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# Optimize text processing\n",
    "def remove_repeated_phrases(text: str) -> str:\n",
    "    return \"\".join(dict.fromkeys(list(text))).replace(\"model\\n\", \"\")"
   ],
   "metadata": {
    "id": "t1OZtgxZkhYu",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:24.684018Z",
     "start_time": "2025-01-18T15:01:24.680788Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "def get_ms_token(client_id, authority, scopes):\n",
    "    # 캐시 파일 경로 설정\n",
    "    cache_file_path = os.path.expanduser('~/.msal_cache.json')\n",
    "\n",
    "    # MSAL Extensions를 사용하여 파일 기반 캐시 생성\n",
    "    persistence = FilePersistence(cache_file_path)\n",
    "    token_cache = PersistedTokenCache(persistence)\n",
    "\n",
    "    # MSAL 앱 생성\n",
    "    app = PublicClientApplication(client_id, authority=authority, token_cache=token_cache)\n",
    "\n",
    "    # 캐시에서 기존 계정 확인\n",
    "    accounts = app.get_accounts()\n",
    "    if accounts:\n",
    "        # 첫 번째 계정 선택 (여러 계정이 있을 경우 적절히 선택)\n",
    "        result = app.acquire_token_silent(scopes, account=accounts[0])\n",
    "        if 'access_token' in result:\n",
    "            print('캐시된 토큰을 사용합니다.')\n",
    "        else:\n",
    "            print('캐시에서 유효한 토큰을 찾을 수 없습니다. 인증을 진행합니다...')\n",
    "    else:\n",
    "        # 디바이스 코드 플로우를 통한 새 인증 진행\n",
    "        flow = app.initiate_device_flow(scopes=scopes)\n",
    "        if 'user_code' not in flow:\n",
    "            raise ValueError('디바이스 플로우 생성에 실패했습니다. 설정을 확인하세요.')\n",
    "        print(f\"다음 URL로 이동하여 코드를 입력하세요: {flow['verification_uri']}\")\n",
    "        print(f\"인증 코드: {flow['user_code']}\")\n",
    "        result = app.acquire_token_by_device_flow(flow)\n",
    "\n",
    "    if 'access_token' in result:\n",
    "        print('인증에 성공했습니다!')\n",
    "        headers = {'Authorization': f\"Bearer {result['access_token']}\"}\n",
    "        return headers\n",
    "    else:\n",
    "        print('인증에 실패했습니다.')\n",
    "        return None"
   ],
   "metadata": {
    "id": "fS7dxuiOdmW3",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:24.696306Z",
     "start_time": "2025-01-18T15:01:24.691256Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "def get_csv_data(graph_api_url, headers):\n",
    "    # 단어 사전 기반 복원 데이터셋 가져오기\n",
    "    dataset_folder_id = '01UUMNEVON2CIOT46PFZHKLFI3QAGBYRUR'  # dataset 폴더\n",
    "    dataset_folder_url = f\"{graph_api_url}/me/drive/items/{dataset_folder_id}/children\"\n",
    "    response = requests.get(dataset_folder_url, headers=headers).json()\n",
    "\n",
    "    files = response.get('value', [])\n",
    "    file_ids = {file['name']: file['id'] for file in files}\n",
    "\n",
    "    # 다운로드할 파일명 목록\n",
    "    target_files = ['train.csv', 'test.csv', 'sample_submission.csv']\n",
    "    responses = {}\n",
    "\n",
    "    for file_name in target_files:\n",
    "        file_id = file_ids.get(file_name)\n",
    "        if file_id:\n",
    "            file_url = f\"{graph_api_url}/me/drive/items/{file_id}/content\"\n",
    "            file_response = requests.get(file_url, headers=headers)\n",
    "            if file_response.status_code == 200:\n",
    "                responses[file_name] = file_response\n",
    "            else:\n",
    "                print(f\"Failed to download {file_name}: {file_response.status_code}\")\n",
    "        else:\n",
    "            print(f\"{file_name} not found in the specified folder.\")\n",
    "\n",
    "    return (responses.get('train.csv'),\n",
    "            responses.get('test.csv'),\n",
    "            responses.get('sample_submission.csv'))"
   ],
   "metadata": {
    "id": "Nku3-O_9ePw7",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:24.708378Z",
     "start_time": "2025-01-18T15:01:24.702959Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and preprocess data\n",
    "def load_data(train_response, test_response, submission_response):\n",
    "    train_csv_data = StringIO(train_response.text)\n",
    "    test_csv_data = StringIO(test_response.text)\n",
    "    submission_data = StringIO(submission_response.text)\n",
    "    train = pd.read_csv(train_csv_data)\n",
    "    test = pd.read_csv(test_csv_data)\n",
    "    submission = pd.read_csv(submission_data)\n",
    "    return train, test, submission"
   ],
   "metadata": {
    "id": "CRfZ3SwJkirw",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:24.719645Z",
     "start_time": "2025-01-18T15:01:24.715640Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# Model and tokenizer initialization\n",
    "def initialize_model(model_name='mindw96/Gemma-2-2B-it-DACON-LLM', device=\"cuda\"):\n",
    "    logging.set_verbosity_info()  # Enables detailed logging\n",
    "    device_map = \"auto\"  # Default behavior, offloads to CPU if necessary\n",
    "\n",
    "    try:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=device_map,\n",
    "        )\n",
    "        print(\"Model loaded successfully on GPU\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Retrying with device_map='cuda'...\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"cuda\",\n",
    "        )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = 'right'\n",
    "    return model, tokenizer\n"
   ],
   "metadata": {
    "id": "XuVclqefkjlj",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:24.731677Z",
     "start_time": "2025-01-18T15:01:24.726672Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Function to decode reviews\n",
    "def decode_reviews(model, tokenizer, test, samples, device=\"cuda\"):\n",
    "    restored_reviews = []\n",
    "    samples = [{\"input\" : train['input'][i], \"output\" : train['output'][i]} for i in range(5)]\n",
    "    system_prompt = f\"You are a helpful assistant specializing in restoring obfuscated Korean reviews. \\\n",
    "\t\t\t\t\tYour task is to transform the given obfuscated Korean review into a clear, correct,\\\n",
    "\t\t\t\t\tand natural-sounding Korean review that reflects its original meaning.\\\n",
    "\t\t\t\t\tBelow are examples of obfuscated Korean reviews and their restored forms:\\n\\n \\\n",
    "\t\t\t\t\tExample, {samples[0]} \\n {samples[1]} \\n {samples[2]} \\n {samples[3]} \\n {samples[4]} \\\n",
    "\t\t\t\t\tSpacing and word length in the output must be restored to the same as in the input.\\\n",
    "\t\t\t\t\tDo not provide any description. Print only in Korean.\"\n",
    "    for _, row in tqdm(test.iterrows(), total=len(test)):\n",
    "        query = row['input']\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": '{}\\ninput: {}, output:'.format(system_prompt, query)}\n",
    "            ]\n",
    "        # messages[0]['content'] = f\"{system_prompt}\\ninput: {query}, output:\"\n",
    "        input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", return_dict=True).to(\"cuda\")\n",
    "        # input_ids = tokenizer(messages[0]['content'], return_tensors=\"pt\").to(device)\n",
    "\n",
    "        outputs = model.generate(\n",
    "            # input_ids['input_ids'],\n",
    "            **input_ids,\n",
    "            max_new_tokens=len(query),\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        result = generated_text[len(messages[0]['content']):].strip()\n",
    "        restored_reviews.append(remove_repeated_phrases(result))\n",
    "\n",
    "    return restored_reviews"
   ],
   "metadata": {
    "id": "BSDIkbibklKa",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:24.743210Z",
     "start_time": "2025-01-18T15:01:24.738209Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Save results to CSV\n",
    "def save_results(restored_reviews, submission_df): # Changed sample_path to submission_df for clarity\n",
    "    submission = submission_df.copy() # Create a copy to avoid modifying the original DataFrame\n",
    "    submission['output'] = restored_reviews\n",
    "    submission.to_csv('/result/submission1.csv', index=False, encoding='utf-8-sig')"
   ],
   "metadata": {
    "id": "paacEA3Rkm7f",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:24.756506Z",
     "start_time": "2025-01-18T15:01:24.750656Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "  # Azure 앱 정보\n",
    "  GRAPH_API_URL = 'https://graph.microsoft.com/v1.0'\n",
    "  CLIENT_ID = 'ef053b61-d7f1-4942-97d4-bb79fa475a01'  # 앱 등록에서 가져온 클라이언트 ID\n",
    "  AUTHORITY = 'https://login.microsoftonline.com/f09a4ef3-978d-434e-89da-a29b9f9f3c32'  # 테넌트 ID 또는 'common'\n",
    "  SCOPES = ['Files.ReadWrite.All']  # 필요 권한 설정"
   ],
   "metadata": {
    "id": "-4hjQjIbgI_T",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:24.767377Z",
     "start_time": "2025-01-18T15:01:24.764021Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "train, test, submission = load_data(*get_csv_data(GRAPH_API_URL, get_ms_token(CLIENT_ID, AUTHORITY, SCOPES)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fo22EHAvkrEq",
    "outputId": "ae15a711-09b4-4b4b-efac-3d695dc94689",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:27.120600Z",
     "start_time": "2025-01-18T15:01:24.775696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐시된 토큰을 사용합니다.\n",
      "인증에 성공했습니다!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "model, tokenizer = initialize_model()"
   ],
   "metadata": {
    "id": "J9BwJ5q6oAqt",
    "ExecuteTime": {
     "end_time": "2025-01-18T15:01:57.917842Z",
     "start_time": "2025-01-18T15:01:27.135048Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\didie\\.cache\\huggingface\\hub\\models--mindw96--Gemma-2-2B-it-DACON-LLM\\snapshots\\1f67bdc6954d5ebe105e1dbaada905fc230c6690\\config.json\n",
      "Model config Gemma2Config {\n",
      "  \"_name_or_path\": \"mindw96/Gemma-2-2B-it-DACON-LLM\",\n",
      "  \"architectures\": [\n",
      "    \"Gemma2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attn_logit_softcapping\": 50.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"cache_implementation\": \"hybrid\",\n",
      "  \"eos_token_id\": [\n",
      "    1,\n",
      "    107\n",
      "  ],\n",
      "  \"final_logit_softcapping\": 30.0,\n",
      "  \"head_dim\": 256,\n",
      "  \"hidden_act\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_size\": 2304,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 9216,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"gemma2\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 26,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"query_pre_attn_scalar\": 256,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.48.0\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 256000\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at C:\\Users\\didie\\.cache\\huggingface\\hub\\models--mindw96--Gemma-2-2B-it-DACON-LLM\\snapshots\\1f67bdc6954d5ebe105e1dbaada905fc230c6690\\model.safetensors.index.json\n",
      "Instantiating Gemma2ForCausalLM model under default dtype torch.float16.\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\logging\\__init__.py\", line 1160, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\logging\\__init__.py\", line 999, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\logging\\__init__.py\", line 703, in format\n",
      "    record.message = record.getMessage()\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\logging\\__init__.py\", line 392, in getMessage\n",
      "    msg = msg % self.args\n",
      "          ~~~~^~~~~~~~~~~\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\didie\\AppData\\Local\\Temp\\ipykernel_13204\\1183351277.py\", line 1, in <module>\n",
      "    model, tokenizer = initialize_model()\n",
      "  File \"C:\\Users\\didie\\AppData\\Local\\Temp\\ipykernel_13204\\797084360.py\", line 7, in initialize_model\n",
      "    model = AutoModelForCausalLM.from_pretrained(\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 564, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4090, in from_pretrained\n",
      "    model = cls(config, *model_args, **model_kwargs)\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\transformers\\models\\gemma2\\modeling_gemma2.py\", line 756, in __init__\n",
      "    super().__init__(config)\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1335, in __init__\n",
      "    self.generation_config = GenerationConfig.from_model_config(config) if self.can_generate() else None\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py\", line 1281, in from_model_config\n",
      "    generation_config = cls.from_dict(config_dict, return_unused_kwargs=False, _from_model_config=True)\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py\", line 1137, in from_dict\n",
      "    config = cls(**{**config_dict, **kwargs})\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py\", line 509, in __init__\n",
      "    self.validate(is_init=True)\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py\", line 789, in validate\n",
      "    logger.warning_once(\n",
      "  File \"C:\\Users\\didie\\anaconda3\\envs\\dacon_vision_ai\\Lib\\site-packages\\transformers\\utils\\logging.py\", line 328, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.'\n",
      "Arguments: (<class 'UserWarning'>,)\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"cache_implementation\": \"hybrid\",\n",
      "  \"eos_token_id\": [\n",
      "    1,\n",
      "    107\n",
      "  ],\n",
      "  \"pad_token_id\": 0,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.32s/it]\n",
      "All model checkpoint weights were used when initializing Gemma2ForCausalLM.\n",
      "\n",
      "All the weights of Gemma2ForCausalLM were initialized from the model checkpoint at mindw96/Gemma-2-2B-it-DACON-LLM.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Gemma2ForCausalLM for predictions without further training.\n",
      "Generation config file not found, using a generation config created from the model config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.model from cache at None\n",
      "loading file tokenizer.json from cache at C:\\Users\\didie\\.cache\\huggingface\\hub\\models--mindw96--Gemma-2-2B-it-DACON-LLM\\snapshots\\1f67bdc6954d5ebe105e1dbaada905fc230c6690\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\didie\\.cache\\huggingface\\hub\\models--mindw96--Gemma-2-2B-it-DACON-LLM\\snapshots\\1f67bdc6954d5ebe105e1dbaada905fc230c6690\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\didie\\.cache\\huggingface\\hub\\models--mindw96--Gemma-2-2B-it-DACON-LLM\\snapshots\\1f67bdc6954d5ebe105e1dbaada905fc230c6690\\tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "restored_reviews = decode_reviews(model, tokenizer, test, train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "HyovrngzoEp-",
    "outputId": "bfdc099e-dd69-4471-a736-6cfd2850f40a",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-18T15:01:57.962852Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1689 [00:00<?, ?it/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "save_results(restored_reviews, submission)"
   ],
   "metadata": {
    "id": "XJt2-8zKoFuz"
   },
   "execution_count": 29,
   "outputs": []
  }
 ]
}
